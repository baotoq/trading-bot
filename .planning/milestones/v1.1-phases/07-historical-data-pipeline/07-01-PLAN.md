---
phase: 07-historical-data-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - TradingBot.ApiService/TradingBot.ApiService.csproj
  - TradingBot.ApiService/Models/IngestionJob.cs
  - TradingBot.ApiService/Infrastructure/Data/TradingBotDbContext.cs
  - TradingBot.ApiService/Infrastructure/CoinGecko/CoinGeckoClient.cs
  - TradingBot.ApiService/Infrastructure/CoinGecko/CoinGeckoOptions.cs
  - TradingBot.ApiService/Infrastructure/CoinGecko/ServiceCollectionExtensions.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/GapDetectionService.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionService.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/IngestionJobQueue.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionBackgroundService.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/Models/IngestionJobStatus.cs
  - TradingBot.ApiService/Application/Services/HistoricalData/Models/DataCoverageStats.cs
autonomous: true

must_haves:
  truths:
    - "CoinGecko daily BTC price data can be fetched for any date range up to 4 years using chunked 90-day API calls"
    - "Fetched OHLC data is persisted in the existing DailyPrice PostgreSQL table with bulk upsert"
    - "Ingestion is incremental -- only missing dates are fetched on re-run"
    - "Gap detection identifies every missing calendar day in a date range using PostgreSQL generate_series"
    - "Ingestion job metadata is persisted in a new IngestionJob table with status tracking"
    - "Background service consumes jobs from a bounded Channel<T> queue (capacity=1)"
    - "CoinGecko API calls are throttled to 25 calls/min with SemaphoreSlim"
    - "Failed API calls retry with exponential backoff via Microsoft.Extensions.Http.Resilience"
  artifacts:
    - path: "TradingBot.ApiService/Infrastructure/CoinGecko/CoinGeckoClient.cs"
      provides: "CoinGecko API client with chunked 90-day fetching and rate limiting"
    - path: "TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionService.cs"
      provides: "Orchestrates fetch, bulk insert, gap detection, and auto-fill"
    - path: "TradingBot.ApiService/Application/Services/HistoricalData/GapDetectionService.cs"
      provides: "PostgreSQL generate_series gap detection and coverage stats"
    - path: "TradingBot.ApiService/Models/IngestionJob.cs"
      provides: "Job entity with status, progress, timestamps, gap count"
    - path: "TradingBot.ApiService/Application/Services/HistoricalData/IngestionJobQueue.cs"
      provides: "Bounded Channel<T> queue with capacity=1 for single job enforcement"
    - path: "TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionBackgroundService.cs"
      provides: "BackgroundService that consumes jobs from queue and runs ingestion"
  key_links:
    - from: "DataIngestionService"
      to: "CoinGeckoClient"
      via: "FetchDailyDataAsync for chunked API calls"
    - from: "DataIngestionService"
      to: "GapDetectionService"
      via: "DetectGapsAsync after bulk insert"
    - from: "DataIngestionService"
      to: "TradingBotDbContext.DailyPrices"
      via: "BulkInsertOrUpdateAsync for high-performance upsert"
    - from: "DataIngestionBackgroundService"
      to: "IngestionJobQueue"
      via: "ReadAllAsync consuming Channel<T>"
    - from: "DataIngestionBackgroundService"
      to: "DataIngestionService"
      via: "RunIngestionAsync per job"
---

<objective>
Build the CoinGecko data fetching infrastructure, ingestion orchestration, gap detection, and background job processing for historical BTC daily prices.

Purpose: This plan creates all the backend services needed to fetch, store, and validate 2-4 years of BTC OHLC data from CoinGecko's free API. It handles rate limiting, chunked requests for daily granularity, bulk database inserts, gap detection, and async job processing -- everything needed before exposing API endpoints in Plan 02.

Output: CoinGeckoClient, DataIngestionService, GapDetectionService, IngestionJobQueue, DataIngestionBackgroundService, IngestionJob entity with migration.
</objective>

<execution_context>
@/Users/baotoq/.claude/get-shit-done/workflows/execute-plan.md
@/Users/baotoq/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-historical-data-pipeline/07-CONTEXT.md
@.planning/phases/07-historical-data-pipeline/07-RESEARCH.md

# Prior phase artifacts referenced
@TradingBot.ApiService/Models/DailyPrice.cs
@TradingBot.ApiService/Infrastructure/Data/TradingBotDbContext.cs
@TradingBot.ApiService/Infrastructure/Hyperliquid/ServiceCollectionExtensions.cs
@TradingBot.ApiService/BuildingBlocks/AuditedEntity.cs
@TradingBot.ApiService/TradingBot.ApiService.csproj
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create IngestionJob entity, CoinGeckoClient with rate-limited chunked fetching, and GapDetectionService</name>
  <files>
    TradingBot.ApiService/TradingBot.ApiService.csproj
    TradingBot.ApiService/Models/IngestionJob.cs
    TradingBot.ApiService/Application/Services/HistoricalData/Models/IngestionJobStatus.cs
    TradingBot.ApiService/Application/Services/HistoricalData/Models/DataCoverageStats.cs
    TradingBot.ApiService/Infrastructure/CoinGecko/CoinGeckoClient.cs
    TradingBot.ApiService/Infrastructure/CoinGecko/CoinGeckoOptions.cs
    TradingBot.ApiService/Infrastructure/CoinGecko/ServiceCollectionExtensions.cs
    TradingBot.ApiService/Infrastructure/Data/TradingBotDbContext.cs
    TradingBot.ApiService/Application/Services/HistoricalData/GapDetectionService.cs
  </files>
  <action>
    **1. Add NuGet packages** to TradingBot.ApiService.csproj:
    - `CoinGecko.Net` (latest 4.x) -- typed CoinGecko API client
    - `EFCore.BulkExtensions` (latest 9.x) -- high-performance bulk inserts for PostgreSQL

    Note: `Microsoft.Extensions.Http.Resilience` (Polly v8) is already in the project. Do NOT add standalone `Polly` package.

    **2. Create IngestionJob entity** at `TradingBot.ApiService/Models/IngestionJob.cs`:
    - Inherit from `AuditedEntity` (gets CreatedAt/UpdatedAt automatically)
    - Properties: `Guid Id` (UUIDv7 via `Guid.CreateVersion7()`), `IngestionJobStatus Status`, `DateOnly StartDate`, `DateOnly EndDate`, `bool Force`, `DateTimeOffset? StartedAt`, `DateTimeOffset? CompletedAt`, `int RecordsFetched`, `int GapsDetected`, `string? ErrorMessage`
    - Id initialized with `Guid.CreateVersion7()` in property initializer

    **3. Create IngestionJobStatus enum** at `Application/Services/HistoricalData/Models/IngestionJobStatus.cs`:
    - Values: `Pending`, `Running`, `Completed`, `CompletedWithGaps`, `Failed`

    **4. Create DataCoverageStats record** at `Application/Services/HistoricalData/Models/DataCoverageStats.cs`:
    - Properties: `DateOnly StartDate`, `DateOnly EndDate`, `int TotalExpectedDays`, `int TotalStoredDays`, `int GapCount`, `List<DateOnly> GapDates`, `decimal CoveragePercent`

    **5. Update TradingBotDbContext:**
    - Add `DbSet<IngestionJob> IngestionJobs` property
    - Add IngestionJob entity configuration in `OnModelCreating`:
      - `HasKey(e => e.Id)`
      - `Property(e => e.Status).HasMaxLength(30).HasConversion<string>()` (store as string like Purchase.Status)
      - `Property(e => e.ErrorMessage).HasMaxLength(2000)`
      - `HasIndex(e => e.Status)` (for querying running jobs)
      - `HasIndex(e => e.CreatedAt)` (for ordering)

    **6. Generate EF Core migration:**
    Run: `cd TradingBot.ApiService && dotnet ef migrations add AddIngestionJob`

    **7. Create CoinGeckoOptions** at `Infrastructure/CoinGecko/CoinGeckoOptions.cs`:
    - Simple class with `string? ApiKey` (optional, for future paid tier)
    - No validation needed (free tier works without key)

    **8. Create CoinGeckoClient** at `Infrastructure/CoinGecko/CoinGeckoClient.cs`:
    - Use the CoinGecko.Net library's `ICoinGeckoRestClient` for API calls
    - Primary constructor with `ICoinGeckoRestClient client, ILogger<CoinGeckoClient> logger`
    - Private `SemaphoreSlim _rateLimiter = new(1, 1)` -- sequential calls with delay between (simplest rate limiting)
    - Public `async Task<List<DailyPrice>> FetchDailyDataAsync(DateOnly startDate, DateOnly endDate, CancellationToken ct)`:
      - Chunk the date range into 90-day windows using a private `ChunkDateRange` helper method
      - For each chunk, call `_client.Api.GetMarketChartRangeAsync("bitcoin", "usd", fromDateTime, toDateTime, ct)` (CoinGecko.Net method for /coins/{id}/market_chart/range)
      - Throttle: after each API call, `await Task.Delay(TimeSpan.FromMilliseconds(2500), ct)` (25 calls/min = 2.4s between calls, round up to 2.5s for safety)
      - Map response to `DailyPrice` entities: extract daily data points from the market chart response. CoinGecko.Net returns `CoinGeckoMarketChart` with `Prices` (list of timestamp+value). Group by date (UTC), use the last price point per day as Close. Set Open=High=Low=Close for simplicity (free tier limitation -- document this). Volume from `TotalVolumes` collection.
      - Set `Symbol = "BTC"`, `Timestamp = DateTimeOffset` from the data point timestamp
      - Deduplicate by Date (keep last per day)
      - Log progress: "Fetched chunk {ChunkNumber}/{TotalChunks}: {StartDate} to {EndDate}, {Count} prices"
      - Return aggregated list of all DailyPrice entities
    - Private `static List<(DateOnly Start, DateOnly End)> ChunkDateRange(DateOnly start, DateOnly end, int chunkSizeDays = 90)` -- breaks range into 90-day windows

    **IMPORTANT:** CoinGecko.Net library uses `CoinGeckoRestClient` as the main client. Check the actual API:
    - Constructor: `new CoinGeckoRestClient()` or via DI
    - Method: `client.Api.GetMarketChartRangeAsync(coinId, vsCurrency, from, to, ct)` -- verify exact method signature from library
    - The response contains `.Data.Prices` (list of price points with timestamps)
    - If library API differs, adapt accordingly but keep the same chunking + rate limiting pattern

    **9. Create CoinGecko ServiceCollectionExtensions** at `Infrastructure/CoinGecko/ServiceCollectionExtensions.cs`:
    - Follow existing `Infrastructure/Hyperliquid/ServiceCollectionExtensions.cs` pattern
    - `public static IServiceCollection AddCoinGecko(this IServiceCollection services, IConfiguration configuration)`
    - Bind `CoinGeckoOptions` from `configuration.GetSection("CoinGecko")`
    - Register `ICoinGeckoRestClient` via CoinGecko.Net's DI integration (CoinGecko.Net provides `.AddCoinGecko()` extension or manual registration)
    - Register `CoinGeckoClient` as scoped
    - If CoinGecko.Net supports HttpClient configuration, add resilience handler similar to Hyperliquid:
      ```
      .AddStandardResilienceHandler(options => {
          options.Retry.MaxRetryAttempts = 3;
          options.Retry.Delay = TimeSpan.FromSeconds(2);
          // etc.
      })
      ```

    **10. Create GapDetectionService** at `Application/Services/HistoricalData/GapDetectionService.cs`:
    - Primary constructor with `TradingBotDbContext db, ILogger<GapDetectionService> logger`
    - `async Task<List<DateOnly>> DetectGapsAsync(DateOnly startDate, DateOnly endDate, string symbol = "BTC", CancellationToken ct = default)`:
      - Use raw SQL with PostgreSQL `generate_series` LEFT JOIN on DailyPrices
      - SQL per research pattern:
        ```sql
        SELECT gs.date::date
        FROM generate_series({startDate}::date, {endDate}::date, '1 day'::interval) AS gs(date)
        LEFT JOIN "DailyPrices" dp ON gs.date::date = dp."Date" AND dp."Symbol" = {symbol}
        WHERE dp."Date" IS NULL
        ORDER BY gs.date
        ```
      - Use `_db.Database.SqlQuery<DateOnly>(...)` with string interpolation (EF parameterization)
      - Log: "Detected {GapCount} missing dates between {Start} and {End}"
    - `async Task<DataCoverageStats> GetCoverageStatsAsync(DateOnly startDate, DateOnly endDate, string symbol = "BTC", CancellationToken ct = default)`:
      - Calculate totalExpectedDays = (endDate - startDate).Days + 1
      - Query storedDays = count of DailyPrices in range
      - Call DetectGapsAsync for gap list
      - Return DataCoverageStats with CoveragePercent = storedDays / totalExpectedDays * 100
  </action>
  <verify>
    1. `dotnet build TradingBot.ApiService` compiles with zero errors
    2. Migration file exists in `TradingBot.ApiService/Infrastructure/Data/Migrations/` with AddIngestionJob name
    3. CoinGecko.Net and EFCore.BulkExtensions packages are in csproj
    4. All new files exist at specified paths
  </verify>
  <done>
    IngestionJob entity with migration, CoinGeckoClient with chunked 90-day fetching and rate limiting, GapDetectionService with PostgreSQL generate_series, and all supporting types compile successfully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create DataIngestionService orchestration, IngestionJobQueue, and DataIngestionBackgroundService</name>
  <files>
    TradingBot.ApiService/Application/Services/HistoricalData/IngestionJobQueue.cs
    TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionService.cs
    TradingBot.ApiService/Application/Services/HistoricalData/DataIngestionBackgroundService.cs
  </files>
  <action>
    **1. Create IngestionJobQueue** at `Application/Services/HistoricalData/IngestionJobQueue.cs`:
    - Wrapper around `Channel<Guid>` (bounded, capacity=1)
    - Constructor creates `Channel.CreateBounded<Guid>(new BoundedChannelOptions(1) { FullMode = BoundedChannelFullMode.DropWrite })` -- DropWrite means TryEnqueue returns false if full (don't block)
    - `ValueTask<bool> TryEnqueueAsync(Guid jobId, CancellationToken ct = default)` -- uses `_channel.Writer.TryWrite(jobId)` (synchronous, no waiting)
    - `IAsyncEnumerable<Guid> ReadAllAsync(CancellationToken ct = default)` -- returns `_channel.Reader.ReadAllAsync(ct)`
    - Register as singleton (lives for entire app lifetime)

    **2. Create DataIngestionService** at `Application/Services/HistoricalData/DataIngestionService.cs`:
    - Primary constructor with `TradingBotDbContext db, CoinGeckoClient coinGecko, GapDetectionService gapDetection, ILogger<DataIngestionService> logger`
    - `async Task RunIngestionAsync(Guid jobId, CancellationToken ct)`:
      - Load IngestionJob from DB by jobId. Throw if not found.
      - Set Status = Running, StartedAt = now, SaveChanges.
      - **try block:**
        - If NOT force mode: check existing data in range, identify missing dates via GapDetectionService.DetectGapsAsync. If no gaps, mark complete immediately.
        - If force mode OR gaps exist: call `coinGecko.FetchDailyDataAsync(startDate, endDate, ct)` to get prices
        - Bulk upsert via `db.BulkInsertOrUpdateAsync(prices, new BulkConfig { ... })`:
          - `UpdateByProperties = [nameof(DailyPrice.Date), nameof(DailyPrice.Symbol)]` (composite key)
          - If force: `PropertiesToIncludeOnUpdate = [Open, High, Low, Close, Volume]` -- update all OHLC fields per user decision
          - If NOT force: `PropertiesToIncludeOnUpdate = []` -- skip updates (only insert new rows)
        - Log: "Bulk upserted {Count} daily prices for job {JobId}"
        - Detect gaps after insert: `gapDetection.DetectGapsAsync(startDate, endDate, "BTC", ct)`
        - **Auto-fill gaps** (per locked decision): If gaps found, iterate each gap date:
          - Try `coinGecko.FetchDailyDataAsync(gapDate, gapDate, ct)` per individual gap
          - If data returned, insert single row via `db.DailyPrices.AddAsync` + SaveChanges
          - Catch and log warning per gap (don't fail entire job for single gap fill failure)
          - Log progress: "Auto-filled {Filled}/{Total} gaps for job {JobId}"
        - Re-detect gaps after auto-fill
        - Set job status: `CompletedWithGaps` if remaining gaps, `Completed` if clean
        - Set CompletedAt, RecordsFetched, GapsDetected, ErrorMessage (if gaps remain)
        - SaveChanges
        - Log: "Job {JobId} completed: {Status}, {Records} records, {Gaps} gaps"
      - **catch block:**
        - Log error: "Job {JobId} failed: {Error}"
        - Set Status = Failed, CompletedAt = now, ErrorMessage = ex.Message
        - SaveChanges (do NOT rethrow -- background service should continue listening)

    **IMPORTANT notes for BulkInsertOrUpdateAsync:**
    - EFCore.BulkExtensions for PostgreSQL may require calling `BulkInsertOrUpdateAsync` on the DbContext directly
    - If the EFCore.BulkExtensions API differs from research code, check: `db.BulkInsertOrUpdateAsync(entities, config)` or `db.BulkInsertOrUpdate(entities, config)` -- some versions use sync-only for PostgreSQL
    - The DailyPrice entity does NOT inherit from BaseEntity (it uses composite key), so ensure BulkConfig handles this correctly
    - If BulkExtensions has issues with composite key, fall back to: raw SQL `INSERT ... ON CONFLICT (date, symbol) DO UPDATE SET ...` via `db.Database.ExecuteSqlRawAsync`

    **3. Create DataIngestionBackgroundService** at `Application/Services/HistoricalData/DataIngestionBackgroundService.cs`:
    - Inherit from `BackgroundService` (NOT TimeBackgroundService -- this is event-driven, not periodic)
    - Primary constructor with `IngestionJobQueue jobQueue, IServiceScopeFactory scopeFactory, ILogger<DataIngestionBackgroundService> logger`
    - `ExecuteAsync`:
      - Log: "DataIngestionBackgroundService started, waiting for jobs"
      - `await foreach (var jobId in jobQueue.ReadAllAsync(stoppingToken))`
        - Log: "Processing ingestion job {JobId}"
        - Create scope: `await using var scope = scopeFactory.CreateAsyncScope()`
        - Resolve `DataIngestionService` from scope
        - Call `await ingestionService.RunIngestionAsync(jobId, stoppingToken)`
        - Catch exceptions and log (service continues listening for next job)
      - Log: "DataIngestionBackgroundService stopped"

    **4. Verify everything compiles:**
    Run `dotnet build TradingBot.ApiService` and fix any compilation errors.
  </action>
  <verify>
    1. `dotnet build TradingBot.ApiService` compiles with zero errors
    2. All three files exist at specified paths
    3. DataIngestionService handles both force and incremental modes
    4. IngestionJobQueue uses bounded Channel with capacity=1
    5. DataIngestionBackgroundService uses IServiceScopeFactory pattern (matching existing codebase convention for background services)
  </verify>
  <done>
    DataIngestionService orchestrates the full ingestion pipeline (fetch, bulk upsert, gap detect, auto-fill). IngestionJobQueue provides bounded single-job queue via Channel<T>. DataIngestionBackgroundService consumes jobs as a long-running BackgroundService. All compile successfully.
  </done>
</task>

</tasks>

<verification>
1. `dotnet build TradingBot.ApiService` -- zero errors
2. All files exist:
   - Models/IngestionJob.cs
   - Infrastructure/CoinGecko/CoinGeckoClient.cs, CoinGeckoOptions.cs, ServiceCollectionExtensions.cs
   - Application/Services/HistoricalData/GapDetectionService.cs
   - Application/Services/HistoricalData/DataIngestionService.cs
   - Application/Services/HistoricalData/IngestionJobQueue.cs
   - Application/Services/HistoricalData/DataIngestionBackgroundService.cs
   - Application/Services/HistoricalData/Models/IngestionJobStatus.cs
   - Application/Services/HistoricalData/Models/DataCoverageStats.cs
3. Migration file exists for AddIngestionJob
4. CoinGecko.Net and EFCore.BulkExtensions in csproj
</verification>

<success_criteria>
- CoinGeckoClient can fetch daily BTC data from CoinGecko using chunked 90-day windows with rate limiting
- DataIngestionService orchestrates full pipeline: fetch -> bulk upsert -> gap detect -> auto-fill -> status update
- GapDetectionService uses PostgreSQL generate_series for accurate gap detection
- IngestionJobQueue provides single-job enforcement via bounded Channel<T>
- DataIngestionBackgroundService consumes and processes jobs as a long-running service
- IngestionJob entity tracks job lifecycle with status, timestamps, progress, and error info
- All code compiles and follows existing codebase patterns (primary constructors, structured logging, scoped services)
</success_criteria>

<output>
After completion, create `.planning/phases/07-historical-data-pipeline/07-01-SUMMARY.md`
</output>
